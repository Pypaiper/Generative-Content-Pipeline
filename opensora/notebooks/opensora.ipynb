{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008a9036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opensora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7586d075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DiskOffloader',\n",
       " '_C',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'offload']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensornvme\n",
    "dir(tensornvme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d8c297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from pprint import pformat\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from colossalai.utils import set_seed\n",
    "from tqdm import tqdm\n",
    "\n",
    "from opensora.acceleration.parallel_states import get_data_parallel_group\n",
    "from opensora.datasets.dataloader import prepare_dataloader\n",
    "from opensora.registry import DATASETS, build_module\n",
    "from opensora.utils.cai import (\n",
    "    get_booster,\n",
    "    get_is_saving_process,\n",
    "    init_inference_environment,\n",
    ")\n",
    "from opensora.utils.config import parse_alias, parse_configs\n",
    "from opensora.utils.inference import (\n",
    "    add_fps_info_to_text,\n",
    "    add_motion_score_to_text,\n",
    "    create_tmp_csv,\n",
    "    modify_option_to_t2i,\n",
    "    process_and_save,\n",
    ")\n",
    "from opensora.utils.logger import create_logger, is_main_process\n",
    "from opensora.utils.misc import log_cuda_max_memory, to_torch_dtype\n",
    "from opensora.utils.prompt_refine import refine_prompts\n",
    "from opensora.utils.sampling import (\n",
    "    SamplingOption,\n",
    "    prepare_api,\n",
    "    prepare_models,\n",
    "    sanitize_sampling_option,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef00c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.inference_mode()\n",
    "def main():\n",
    "    # ======================================================\n",
    "    # 1. configs & runtime variables\n",
    "    # ======================================================\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    # == parse configs ==\n",
    "    cfg = parse_configs()\n",
    "    cfg = parse_alias(cfg)\n",
    "\n",
    "    # == device and dtype ==\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype = to_torch_dtype(cfg.get(\"dtype\", \"bf16\"))\n",
    "    seed = cfg.get(\"seed\", 1024)\n",
    "    if seed is not None:\n",
    "        set_seed(seed)\n",
    "\n",
    "    # == init distributed env ==\n",
    "    init_inference_environment()\n",
    "    logger = create_logger()\n",
    "    logger.info(\"Inference configuration:\\n %s\", pformat(cfg.to_dict()))\n",
    "    is_saving_process = get_is_saving_process(cfg)\n",
    "    booster = get_booster(cfg)\n",
    "    booster_ae = get_booster(cfg, ae=True)\n",
    "\n",
    "    # ======================================================\n",
    "    # 2. build dataset and dataloader\n",
    "    # ======================================================\n",
    "    logger.info(\"Building dataset...\")\n",
    "\n",
    "    # save directory\n",
    "    save_dir = cfg.save_dir\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # == build dataset ==\n",
    "    if cfg.get(\"prompt\"):\n",
    "        cfg.dataset.data_path = create_tmp_csv(save_dir, cfg.prompt, cfg.get(\"ref\", None), create=is_main_process())\n",
    "    dist.barrier()\n",
    "    dataset = build_module(cfg.dataset, DATASETS)\n",
    "\n",
    "    # range selection\n",
    "    start_index = cfg.get(\"start_index\", 0)\n",
    "    end_index = cfg.get(\"end_index\", None)\n",
    "    if end_index is None:\n",
    "        end_index = start_index + cfg.get(\"num_samples\", len(dataset.data) + 1)\n",
    "    dataset.data = dataset.data[start_index:end_index]\n",
    "    logger.info(\"Dataset contains %s samples.\", len(dataset))\n",
    "\n",
    "    # == build dataloader ==\n",
    "    dataloader_args = dict(\n",
    "        dataset=dataset,\n",
    "        batch_size=cfg.get(\"batch_size\", 1),\n",
    "        num_workers=cfg.get(\"num_workers\", 4),\n",
    "        seed=cfg.get(\"seed\", 1024),\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        process_group=get_data_parallel_group(),\n",
    "        prefetch_factor=cfg.get(\"prefetch_factor\", None),\n",
    "    )\n",
    "    dataloader, _ = prepare_dataloader(**dataloader_args)\n",
    "\n",
    "    # == prepare default params ==\n",
    "    sampling_option = SamplingOption(**cfg.sampling_option)\n",
    "    sampling_option = sanitize_sampling_option(sampling_option)\n",
    "\n",
    "    cond_type = cfg.get(\"cond_type\", \"t2v\")\n",
    "    prompt_refine = cfg.get(\"prompt_refine\", False)\n",
    "    fps_save = cfg.get(\"fps_save\", 16)\n",
    "    num_sample = cfg.get(\"num_sample\", 1)\n",
    "\n",
    "    type_name = \"image\" if cfg.sampling_option.num_frames == 1 else \"video\"\n",
    "    sub_dir = f\"{type_name}_{cfg.sampling_option.resolution}\"\n",
    "    os.makedirs(os.path.join(save_dir, sub_dir), exist_ok=True)\n",
    "    use_t2i2v = cfg.get(\"use_t2i2v\", False)\n",
    "    img_sub_dir = os.path.join(sub_dir, \"generated_condition\")\n",
    "    if use_t2i2v:\n",
    "        os.makedirs(os.path.join(save_dir, sub_dir, \"generated_condition\"), exist_ok=True)\n",
    "\n",
    "    # ======================================================\n",
    "    # 3. build model\n",
    "    # ======================================================\n",
    "    logger.info(\"Building models...\")\n",
    "\n",
    "    # == build flux model ==\n",
    "    model, model_ae, model_t5, model_clip, optional_models = prepare_models(\n",
    "        cfg, device, dtype, offload_model=cfg.get(\"offload_model\", False)\n",
    "    )\n",
    "    log_cuda_max_memory(\"build model\")\n",
    "\n",
    "    if booster:\n",
    "        model, _, _, _, _ = booster.boost(model=model)\n",
    "        model = model.unwrap()\n",
    "    if booster_ae:\n",
    "        model_ae, _, _, _, _ = booster_ae.boost(model=model_ae)\n",
    "        model_ae = model_ae.unwrap()\n",
    "\n",
    "    api_fn = prepare_api(model, model_ae, model_t5, model_clip, optional_models)\n",
    "\n",
    "    # prepare image flux model if t2i2v\n",
    "    if use_t2i2v:\n",
    "        api_fn_img = prepare_api(\n",
    "            optional_models[\"img_flux\"], optional_models[\"img_flux_ae\"], model_t5, model_clip, optional_models\n",
    "        )\n",
    "\n",
    "    # ======================================================\n",
    "    # 4. inference\n",
    "    # ======================================================\n",
    "    for epoch in range(num_sample):  # generate multiple samples with different seeds\n",
    "        dataloader_iter = iter(dataloader)\n",
    "        with tqdm(\n",
    "            enumerate(dataloader_iter, start=0),\n",
    "            desc=\"Inference progress\",\n",
    "            disable=not is_main_process(),\n",
    "            initial=0,\n",
    "            total=len(dataloader),\n",
    "        ) as pbar:\n",
    "            for _, batch in pbar:\n",
    "                original_text = batch.pop(\"text\")\n",
    "                if use_t2i2v:\n",
    "                    batch[\"text\"] = original_text if not prompt_refine else refine_prompts(original_text, type=\"t2i\")\n",
    "                    sampling_option_t2i = modify_option_to_t2i(\n",
    "                        sampling_option,\n",
    "                        distilled=True,\n",
    "                        img_resolution=cfg.get(\"img_resolution\", \"768px\"),\n",
    "                    )\n",
    "                    if cfg.get(\"offload_model\", False):\n",
    "                        model_move_start = time.time()\n",
    "                        model = model.to(\"cpu\", dtype)\n",
    "                        model_ae = model_ae.to(\"cpu\", dtype)\n",
    "                        optional_models[\"img_flux\"].to(device, dtype)\n",
    "                        optional_models[\"img_flux_ae\"].to(device, dtype)\n",
    "                        logger.info(\n",
    "                            \"offload video diffusion model to cpu, load image flux model to gpu: %s s\",\n",
    "                            time.time() - model_move_start,\n",
    "                        )\n",
    "\n",
    "                    logger.info(\"Generating image condition by flux...\")\n",
    "                    x_cond = api_fn_img(\n",
    "                        sampling_option_t2i,\n",
    "                        \"t2v\",\n",
    "                        seed=sampling_option.seed + epoch if sampling_option.seed else None,\n",
    "                        channel=cfg[\"img_flux\"][\"in_channels\"],\n",
    "                        **batch,\n",
    "                    ).cpu()\n",
    "\n",
    "                    # save image to disk\n",
    "                    batch[\"name\"] = process_and_save(\n",
    "                        x_cond,\n",
    "                        batch,\n",
    "                        cfg,\n",
    "                        img_sub_dir,\n",
    "                        sampling_option_t2i,\n",
    "                        epoch,\n",
    "                        start_index,\n",
    "                        saving=is_saving_process,\n",
    "                    )\n",
    "                    dist.barrier()\n",
    "\n",
    "                    if cfg.get(\"offload_model\", False):\n",
    "                        model_move_start = time.time()\n",
    "                        model = model.to(device, dtype)\n",
    "                        model_ae = model_ae.to(device, dtype)\n",
    "                        optional_models[\"img_flux\"].to(\"cpu\", dtype)\n",
    "                        optional_models[\"img_flux_ae\"].to(\"cpu\", dtype)\n",
    "                        logger.info(\n",
    "                            \"load video diffusion model to gpu, offload image flux model to cpu: %s s\",\n",
    "                            time.time() - model_move_start,\n",
    "                        )\n",
    "\n",
    "                    ref_dir = os.path.join(save_dir, os.path.join(sub_dir, \"generated_condition\"))\n",
    "                    batch[\"ref\"] = [os.path.join(ref_dir, f\"{x}.png\") for x in batch[\"name\"]]\n",
    "                    cond_type = \"i2v_head\"\n",
    "\n",
    "                batch[\"text\"] = original_text\n",
    "                if prompt_refine:\n",
    "                    batch[\"text\"] = refine_prompts(\n",
    "                        original_text, type=\"t2v\" if cond_type == \"t2v\" else \"t2i\", image_paths=batch.get(\"ref\", None)\n",
    "                    )\n",
    "                batch[\"text\"] = add_fps_info_to_text(batch.pop(\"text\"), fps=fps_save)\n",
    "                if \"motion_score\" in cfg:\n",
    "                    batch[\"text\"] = add_motion_score_to_text(batch.pop(\"text\"), cfg.get(\"motion_score\", 5))\n",
    "\n",
    "                logger.info(\"Generating video...\")\n",
    "                x = api_fn(\n",
    "                    sampling_option,\n",
    "                    cond_type,\n",
    "                    seed=sampling_option.seed + epoch if sampling_option.seed else None,\n",
    "                    patch_size=cfg.get(\"patch_size\", 2),\n",
    "                    save_prefix=cfg.get(\"save_prefix\", \"\"),\n",
    "                    channel=cfg[\"model\"][\"in_channels\"],\n",
    "                    **batch,\n",
    "                ).cpu()\n",
    "\n",
    "                if is_saving_process:\n",
    "                    process_and_save(x, batch, cfg, sub_dir, sampling_option, epoch, start_index)\n",
    "                dist.barrier()\n",
    "\n",
    "    logger.info(\"Inference finished.\")\n",
    "    log_cuda_max_memory(\"inference\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
