{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b916cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93fe66b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148b99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from pprint import pformat\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from colossalai.utils import set_seed\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import snapshot_download\n",
    "from opensora.acceleration.parallel_states import get_data_parallel_group\n",
    "from opensora.datasets.dataloader import prepare_dataloader\n",
    "from opensora.registry import DATASETS, build_module\n",
    "from opensora.utils.cai import (\n",
    "    get_booster,\n",
    "    get_is_saving_process,\n",
    "    init_inference_environment,\n",
    ")\n",
    "from opensora.utils.config import parse_alias, parse_configs\n",
    "from opensora.utils.inference import (\n",
    "    add_fps_info_to_text,\n",
    "    add_motion_score_to_text,\n",
    "    create_tmp_csv,\n",
    "    modify_option_to_t2i,\n",
    "    process_and_save,\n",
    ")\n",
    "from opensora.utils.logger import create_logger, is_main_process\n",
    "from opensora.utils.misc import log_cuda_max_memory, to_torch_dtype\n",
    "from opensora.utils.prompt_refine import refine_prompts\n",
    "from opensora.utils.sampling import (\n",
    "    SamplingOption,\n",
    "    prepare_api,\n",
    "    prepare_models,\n",
    "    sanitize_sampling_option,\n",
    ")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 1. configs & runtime variables\n",
    "# ======================================================\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# == parse configs ==\n",
    "cfg = parse_configs(\"../configs/diffusion/inference/t2i2v_256px.py\")\n",
    "cfg = parse_alias(cfg)\n",
    "cfg[\"prompt\"] = \"raining, sea\"\n",
    "cfg[\"ref\"] = \"../assets/texts/i2v.png\"\n",
    "\n",
    "model_path = Path(\"models\")\n",
    "if not model_path.exists():\n",
    "    model_path.mkdir()\n",
    "    REPO_ID = \"hpcai-tech/Open-Sora-v2\"\n",
    "    snapshot_download(repo_id=REPO_ID,local_dir=model_path) \n",
    "\n",
    "    \n",
    "# == device and dtype ==\n",
    "\n",
    "device =  \"cpu\" #if not torch.cuda.is_available() else \"cuda\" \n",
    "dtype = to_torch_dtype(cfg.get(\"dtype\", \"bf16\"))\n",
    "seed = cfg.get(\"seed\", 1024)\n",
    "if seed is not None:\n",
    "    set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c2f79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07/29/25 17:17:09] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> colossalai - colossalai - INFO:                                                       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/opt/conda/envs/opensora/lib/python3.10/site-packages/colossalai/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">initialize.py</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span>     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         launch                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07/29/25 17:17:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m colossalai - colossalai - INFO:                                                       \n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35m/opt/conda/envs/opensora/lib/python3.10/site-packages/colossalai/\u001b[0m\u001b[95minitialize.py\u001b[0m:\u001b[1;36m75\u001b[0m     \n",
       "\u001b[2;36m                    \u001b[0m         launch                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> colossalai - colossalai - INFO: Distributed environment is initialized, world size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m colossalai - colossalai - INFO: Distributed environment is initialized, world size: \u001b[1;36m1\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# == init distributed env ==\n",
    "os.environ['LOCAL_RANK'] = \"0\"\n",
    "init_inference_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32de4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-07-29 17:17:11\u001b[0m] Inference configuration:\n",
      " {'ae': {'from_pretrained': 'models/hunyuan_vae.safetensors',\n",
      "        'in_channels': 3,\n",
      "        'latent_channels': 16,\n",
      "        'layers_per_block': 2,\n",
      "        'out_channels': 3,\n",
      "        'type': 'hunyuan_vae',\n",
      "        'use_spatial_tiling': True,\n",
      "        'use_temporal_tiling': False},\n",
      " 'batch_size': 1,\n",
      " 'clip': {'from_pretrained': 'models/openai/clip-vit-large-patch14',\n",
      "          'max_length': 77,\n",
      "          'type': 'text_embedder'},\n",
      " 'cond_type': 't2v',\n",
      " 'config_path': '../configs/diffusion/inference/t2i2v_256px.py',\n",
      " 'dataset': {'type': 'text'},\n",
      " 'dtype': 'bf16',\n",
      " 'fps_save': 24,\n",
      " 'img_flux': {'axes_dim': [16, 56, 56],\n",
      "              'cond_embed': False,\n",
      "              'context_in_dim': 4096,\n",
      "              'depth': 19,\n",
      "              'depth_single_blocks': 38,\n",
      "              'from_pretrained': './models/flux1-dev.safetensors',\n",
      "              'guidance_embed': True,\n",
      "              'hidden_size': 3072,\n",
      "              'in_channels': 64,\n",
      "              'mlp_ratio': 4.0,\n",
      "              'num_heads': 24,\n",
      "              'qkv_bias': True,\n",
      "              'theta': 10000,\n",
      "              'type': 'flux',\n",
      "              'vec_in_dim': 768},\n",
      " 'img_flux_ae': {'ch': 128,\n",
      "                 'ch_mult': [1, 2, 4, 4],\n",
      "                 'from_pretrained': 'models/flux1-dev-ae.safetensors',\n",
      "                 'in_channels': 3,\n",
      "                 'num_res_blocks': 2,\n",
      "                 'out_ch': 3,\n",
      "                 'resolution': 256,\n",
      "                 'scale_factor': 0.3611,\n",
      "                 'shift_factor': 0.1159,\n",
      "                 'type': 'autoencoder_2d',\n",
      "                 'z_channels': 16},\n",
      " 'img_resolution': '768px',\n",
      " 'model': {'axes_dim': [16, 56, 56],\n",
      "           'cond_embed': True,\n",
      "           'context_in_dim': 4096,\n",
      "           'depth': 19,\n",
      "           'depth_single_blocks': 38,\n",
      "           'from_pretrained': 'models/Open_Sora_v2.safetensors',\n",
      "           'fused_qkv': False,\n",
      "           'guidance_embed': False,\n",
      "           'hidden_size': 3072,\n",
      "           'in_channels': 64,\n",
      "           'mlp_ratio': 4.0,\n",
      "           'num_heads': 24,\n",
      "           'qkv_bias': True,\n",
      "           'theta': 10000,\n",
      "           'type': 'flux',\n",
      "           'use_liger_rope': True,\n",
      "           'vec_in_dim': 768},\n",
      " 'motion_score': '4',\n",
      " 'prompt': 'raining, sea',\n",
      " 'ref': '../assets/texts/i2v.png',\n",
      " 'sampling_option': {'aspect_ratio': '16:9',\n",
      "                     'guidance': 7.5,\n",
      "                     'guidance_img': 3.0,\n",
      "                     'image_osci': True,\n",
      "                     'is_causal_vae': True,\n",
      "                     'method': 'i2v',\n",
      "                     'num_frames': 129,\n",
      "                     'num_steps': 50,\n",
      "                     'resolution': '256px',\n",
      "                     'scale_temporal_osci': True,\n",
      "                     'seed': None,\n",
      "                     'shift': True,\n",
      "                     'temporal_reduction': 4,\n",
      "                     'text_osci': True},\n",
      " 'save_dir': 'samples',\n",
      " 'seed': 42,\n",
      " 't5': {'from_pretrained': 'models/google/t5-v1_1-xxl',\n",
      "        'max_length': 512,\n",
      "        'shardformer': True,\n",
      "        'type': 'text_embedder'},\n",
      " 'use_t2i2v': True}\n"
     ]
    }
   ],
   "source": [
    "logger = create_logger()\n",
    "logger.info(\"Inference configuration:\\n %s\", pformat(cfg.to_dict()))\n",
    "is_saving_process = get_is_saving_process(cfg)\n",
    "booster = get_booster(cfg)\n",
    "booster_ae = get_booster(cfg, ae=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d4ce984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-07-29 17:17:24\u001b[0m] Building dataset...\n",
      "[\u001b[34m2025-07-29 17:17:24\u001b[0m] Dataset contains 1 samples.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======================================================\n",
    "# 2. build dataset and dataloader\n",
    "# ======================================================\n",
    "logger.info(\"Building dataset...\")\n",
    "\n",
    "# save directory\n",
    "save_dir = cfg.save_dir\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# == build dataset ==\n",
    "if cfg.get(\"prompt\"):\n",
    "    cfg.dataset.data_path = create_tmp_csv(save_dir, cfg.prompt, cfg.get(\"ref\", None), create=is_main_process())\n",
    "dist.barrier()\n",
    "dataset = build_module(cfg.dataset, DATASETS)\n",
    "\n",
    "# range selection\n",
    "start_index = cfg.get(\"start_index\", 0)\n",
    "end_index = cfg.get(\"end_index\", None)\n",
    "if end_index is None:\n",
    "    end_index = start_index + cfg.get(\"num_samples\", len(dataset.data) + 1)\n",
    "dataset.data = dataset.data[start_index:end_index]\n",
    "logger.info(\"Dataset contains %s samples.\", len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6936ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# == build dataloader ==\n",
    "dataloader_args = dict(\n",
    "    dataset=dataset,\n",
    "    batch_size=cfg.get(\"batch_size\", 1),\n",
    "    num_workers=cfg.get(\"num_workers\", 4),\n",
    "    seed=cfg.get(\"seed\", 1024),\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    pin_memory=True,\n",
    "    process_group=get_data_parallel_group(),\n",
    "    prefetch_factor=cfg.get(\"prefetch_factor\", None),\n",
    ")\n",
    "dataloader, _ = prepare_dataloader(**dataloader_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab76543",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# == prepare default params ==\n",
    "sampling_option = SamplingOption(**cfg.sampling_option)\n",
    "sampling_option = sanitize_sampling_option(sampling_option)\n",
    "\n",
    "cond_type = cfg.get(\"cond_type\", \"t2v\")\n",
    "prompt_refine = cfg.get(\"prompt_refine\", False)\n",
    "fps_save = cfg.get(\"fps_save\", 16)\n",
    "num_sample = cfg.get(\"num_sample\", 1)\n",
    "\n",
    "type_name = \"image\" if cfg.sampling_option.num_frames == 1 else \"video\"\n",
    "sub_dir = f\"{type_name}_{cfg.sampling_option.resolution}\"\n",
    "os.makedirs(os.path.join(save_dir, sub_dir), exist_ok=True)\n",
    "use_t2i2v = cfg.get(\"use_t2i2v\", False)\n",
    "img_sub_dir = os.path.join(sub_dir, \"generated_condition\")\n",
    "if use_t2i2v:\n",
    "    os.makedirs(os.path.join(save_dir, sub_dir, \"generated_condition\"), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410995ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================================================\n",
    "# 3. build model\n",
    "# ======================================================\n",
    "logger.info(\"Building models...\")\n",
    "\n",
    "# == build flux model ==\n",
    "model, model_ae, model_t5, model_clip, optional_models = prepare_models(\n",
    "    cfg, device, dtype, offload_model=cfg.get(\"offload_model\", False)\n",
    ")\n",
    "log_cuda_max_memory(\"build model\")\n",
    "\n",
    "# if booster:\n",
    "#     model, _, _, _, _ = booster.boost(model=model)\n",
    "#     model = model.unwrap()\n",
    "# if booster_ae:\n",
    "#     model_ae, _, _, _, _ = booster_ae.boost(model=model_ae)\n",
    "#     model_ae = model_ae.unwrap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4defe52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_fn = prepare_api(model, model_ae, model_t5, model_clip, optional_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a8c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare image flux model if t2i2v\n",
    "if use_t2i2v:\n",
    "    api_fn_img = prepare_api(\n",
    "        optional_models[\"img_flux\"], optional_models[\"img_flux_ae\"], model_t5, model_clip, optional_models\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================================================\n",
    "# 4. inference\n",
    "# ======================================================\n",
    "for epoch in range(num_sample):  # generate multiple samples with different seeds\n",
    "    dataloader_iter = iter(dataloader)\n",
    "    with tqdm(\n",
    "        enumerate(dataloader_iter, start=0),\n",
    "        desc=\"Inference progress\",\n",
    "        disable=not is_main_process(),\n",
    "        initial=0,\n",
    "        total=len(dataloader),\n",
    "    ) as pbar:\n",
    "        for _, batch in pbar:\n",
    "            original_text = batch.pop(\"text\")\n",
    "            if use_t2i2v:\n",
    "                batch[\"text\"] = original_text if not prompt_refine else refine_prompts(original_text, type=\"t2i\")\n",
    "                sampling_option_t2i = modify_option_to_t2i(\n",
    "                    sampling_option,\n",
    "                    distilled=True,\n",
    "                    img_resolution=cfg.get(\"img_resolution\", \"768px\"),\n",
    "                )\n",
    "                if cfg.get(\"offload_model\", False):\n",
    "                    model_move_start = time.time()\n",
    "                    model = model.to(\"cpu\", dtype)\n",
    "                    model_ae = model_ae.to(\"cpu\", dtype)\n",
    "                    optional_models[\"img_flux\"].to(device, dtype)\n",
    "                    optional_models[\"img_flux_ae\"].to(device, dtype)\n",
    "                    logger.info(\n",
    "                        \"offload video diffusion model to cpu, load image flux model to gpu: %s s\",\n",
    "                        time.time() - model_move_start,\n",
    "                    )\n",
    "\n",
    "                logger.info(\"Generating image condition by flux...\")\n",
    "                x_cond = api_fn_img(\n",
    "                    sampling_option_t2i,\n",
    "                    \"t2v\",\n",
    "                    seed=sampling_option.seed + epoch if sampling_option.seed else None,\n",
    "                    channel=cfg[\"img_flux\"][\"in_channels\"],\n",
    "                    **batch,\n",
    "                ).cpu()\n",
    "\n",
    "                # save image to disk\n",
    "                batch[\"name\"] = process_and_save(\n",
    "                    x_cond,\n",
    "                    batch,\n",
    "                    cfg,\n",
    "                    img_sub_dir,\n",
    "                    sampling_option_t2i,\n",
    "                    epoch,\n",
    "                    start_index,\n",
    "                    saving=is_saving_process,\n",
    "                )\n",
    "                dist.barrier()\n",
    "\n",
    "                if cfg.get(\"offload_model\", False):\n",
    "                    model_move_start = time.time()\n",
    "                    model = model.to(device, dtype)\n",
    "                    model_ae = model_ae.to(device, dtype)\n",
    "                    optional_models[\"img_flux\"].to(\"cpu\", dtype)\n",
    "                    optional_models[\"img_flux_ae\"].to(\"cpu\", dtype)\n",
    "                    logger.info(\n",
    "                        \"load video diffusion model to gpu, offload image flux model to cpu: %s s\",\n",
    "                        time.time() - model_move_start,\n",
    "                    )\n",
    "\n",
    "                ref_dir = os.path.join(save_dir, os.path.join(sub_dir, \"generated_condition\"))\n",
    "                batch[\"ref\"] = [os.path.join(ref_dir, f\"{x}.png\") for x in batch[\"name\"]]\n",
    "                cond_type = \"i2v_head\"\n",
    "\n",
    "            batch[\"text\"] = original_text\n",
    "            if prompt_refine:\n",
    "                batch[\"text\"] = refine_prompts(\n",
    "                    original_text, type=\"t2v\" if cond_type == \"t2v\" else \"t2i\", image_paths=batch.get(\"ref\", None)\n",
    "                )\n",
    "            batch[\"text\"] = add_fps_info_to_text(batch.pop(\"text\"), fps=fps_save)\n",
    "            if \"motion_score\" in cfg:\n",
    "                batch[\"text\"] = add_motion_score_to_text(batch.pop(\"text\"), cfg.get(\"motion_score\", 5))\n",
    "\n",
    "            logger.info(\"Generating video...\")\n",
    "            x = api_fn(\n",
    "                sampling_option,\n",
    "                cond_type,\n",
    "                seed=sampling_option.seed + epoch if sampling_option.seed else None,\n",
    "                patch_size=cfg.get(\"patch_size\", 2),\n",
    "                save_prefix=cfg.get(\"save_prefix\", \"\"),\n",
    "                channel=cfg[\"model\"][\"in_channels\"],\n",
    "                **batch,\n",
    "            ).cpu()\n",
    "\n",
    "            if is_saving_process:\n",
    "                process_and_save(x, batch, cfg, sub_dir, sampling_option, epoch, start_index)\n",
    "            dist.barrier()\n",
    "\n",
    "logger.info(\"Inference finished.\")\n",
    "log_cuda_max_memory(\"inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9763f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa534556",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# == get dtype & device ==\n",
    "dtype = to_torch_dtype(cfg.get(\"dtype\", \"bf16\"))\n",
    "device, coordinator = setup_device()\n",
    "grad_ckpt_buffer_size = cfg.get(\"grad_ckpt_buffer_size\", 0)\n",
    "if grad_ckpt_buffer_size > 0:\n",
    "    GLOBAL_ACTIVATION_MANAGER.setup_buffer(grad_ckpt_buffer_size, dtype)\n",
    "checkpoint_io = CheckpointIO()\n",
    "set_seed(cfg.get(\"seed\", 1024))\n",
    "PinMemoryCache.force_dtype = dtype\n",
    "pin_memory_cache_pre_alloc_numels = cfg.get(\"pin_memory_cache_pre_alloc_numels\", None)\n",
    "PinMemoryCache.pre_alloc_numels = pin_memory_cache_pre_alloc_numels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c898f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"models\") / \"opensora\"\n",
    "if not model_path.exists():\n",
    "    model_path.mkdir()\n",
    "    REPO_ID = \"hpcai-tech/Open-Sora-v2\"\n",
    "    snapshot_download(repo_id=REPO_ID,local_dir=model_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf325ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# == init ColossalAI booster ==\n",
    "plugin_type = cfg.get(\"plugin\", \"zero2\")\n",
    "cfg[\"plugin_config\"] = cfg.get(\"plugin_config\", {})\n",
    "plugin_kwargs = {}\n",
    "if plugin_type == \"hybrid\":\n",
    "    plugin_kwargs[\"custom_policy\"] = MMDiTPolicy\n",
    "plugin = create_colossalai_plugin(\n",
    "    plugin=plugin_type,\n",
    "    dtype=cfg.get(\"dtype\", \"bf16\"),\n",
    "    grad_clip=cfg.get(\"grad_clip\", 0),\n",
    "    **cfg[\"plugin_config\"],\n",
    "    **plugin_kwargs,\n",
    ")\n",
    "booster = Booster(plugin=plugin)\n",
    "\n",
    "seq_align = cfg[\"plugin_config\"].get(\"sp_size\", 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ac24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == init exp_dir ==\n",
    "exp_name, exp_dir = create_experiment_workspace(\n",
    "    cfg.get(\"outputs\", \"./outputs\"),\n",
    "    model_name=config_to_name(cfg),\n",
    "    config=cfg.to_dict(),\n",
    "    exp_name=cfg.get(\"exp_name\", None),  # useful for automatic restart to specify the exp_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d261c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if is_log_process(plugin_type, plugin_config):\n",
    "#     print(f\"changing {exp_dir} to share\")\n",
    "#     os.system(f\"chgrp -R share {exp_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84740070",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = create_logger(exp_dir)\n",
    "logger.info(\"Training configuration:\\n %s\", pformat(cfg.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa04d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_writer = None\n",
    "if coordinator.is_master():\n",
    "    tb_writer = create_tensorboard_writer(exp_dir)\n",
    "    if cfg.get(\"wandb\", False):\n",
    "        wandb.init(\n",
    "            project=cfg.get(\"wandb_project\", \"Open-Sora\"),\n",
    "            name=exp_name,\n",
    "            config=cfg.to_dict(),\n",
    "            dir=exp_dir,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07dcac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_gpus = dist.get_world_size() if dist.is_initialized() else 1\n",
    "tp_size = cfg[\"plugin_config\"].get(\"tp_size\", 1)\n",
    "sp_size = cfg[\"plugin_config\"].get(\"sp_size\", 1)\n",
    "pp_size = cfg[\"plugin_config\"].get(\"pp_size\", 1)\n",
    "num_groups = num_gpus // (tp_size * sp_size * pp_size)\n",
    "logger.info(\"Number of GPUs: %s\", num_gpus)\n",
    "logger.info(\"Number of groups: %s\", num_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b5eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg[\"prompt\"] = \"raining, sea\"\n",
    "cfg[\"ref\"] = \"../assets/texts/i2v.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40967723",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf9700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================================================\n",
    "# 2. build dataset and dataloader\n",
    "# ======================================================\n",
    "logger.info(\"Building dataset...\")\n",
    "# == build dataset ==\n",
    "dataset = build_module(cfg.dataset, DATASETS)\n",
    "# logger.info(\"Dataset contains %s samples.\", len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b35867",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # ======================================================\n",
    "# # 2. build dataset and dataloader\n",
    "# # ======================================================\n",
    "# logger.info(\"Building dataset...\")\n",
    "# # == build dataset ==\n",
    "# dataset = build_module(cfg.dataset, DATASETS)\n",
    "# logger.info(\"Dataset contains %s samples.\", len(dataset))\n",
    "\n",
    "# # == build dataloader ==\n",
    "# cache_pin_memory = pin_memory_cache_pre_alloc_numels is not None\n",
    "# dataloader_args = dict(\n",
    "#     dataset=dataset,\n",
    "#     batch_size=cfg.get(\"batch_size\", None),\n",
    "#     num_workers=cfg.get(\"num_workers\", 4),\n",
    "#     seed=cfg.get(\"seed\", 1024),\n",
    "#     shuffle=True,\n",
    "#     drop_last=True,\n",
    "#     pin_memory=True,\n",
    "#     process_group=get_data_parallel_group(),\n",
    "#     prefetch_factor=cfg.get(\"prefetch_factor\", None),\n",
    "#     cache_pin_memory=cache_pin_memory,\n",
    "#     num_groups=num_groups,\n",
    "# )\n",
    "# print_mem(\"before prepare_dataloader\")\n",
    "# dataloader, sampler = prepare_dataloader(\n",
    "#     bucket_config=cfg.get(\"bucket_config\", None),\n",
    "#     num_bucket_build_workers=cfg.get(\"num_bucket_build_workers\", 1),\n",
    "#     **dataloader_args,\n",
    "# )\n",
    "# print_mem(\"after prepare_dataloader\")\n",
    "# num_steps_per_epoch = len(dataloader)\n",
    "# dataset.to_efficient()\n",
    "\n",
    "# # ======================================================\n",
    "# # 3. build model\n",
    "# # ======================================================\n",
    "# logger.info(\"Building models...\")\n",
    "\n",
    "# # == build model model ==\n",
    "# model = build_module(cfg.model, MODELS, device_map=device, torch_dtype=dtype).train()\n",
    "# if cfg.get(\"grad_checkpoint\", True):\n",
    "#     set_grad_checkpoint(model)\n",
    "# log_cuda_memory(\"diffusion\")\n",
    "# log_model_params(model)\n",
    "\n",
    "# # == build EMA model ==\n",
    "# use_lora = cfg.get(\"lora_config\", None) is not None\n",
    "# if cfg.get(\"ema_decay\", None) is not None and not use_lora:\n",
    "#     ema = deepcopy(model).cpu().eval().requires_grad_(False)\n",
    "#     ema_shape_dict = record_model_param_shape(ema)\n",
    "#     logger.info(\"EMA model created.\")\n",
    "# else:\n",
    "#     ema = ema_shape_dict = None\n",
    "#     logger.info(\"No EMA model created.\")\n",
    "# log_cuda_memory(\"EMA\")\n",
    "\n",
    "# # == enable LoRA ==\n",
    "# if use_lora:\n",
    "#     lora_config = LoraConfig(**cfg.get(\"lora_config\", None))\n",
    "#     model = booster.enable_lora(\n",
    "#         model=model,\n",
    "#         lora_config=lora_config,\n",
    "#         pretrained_dir=cfg.get(\"lora_checkpoint\", None),\n",
    "#     )\n",
    "#     log_cuda_memory(\"lora\")\n",
    "#     log_model_params(model)\n",
    "\n",
    "# if not cfg.get(\"cached_video\", False):\n",
    "#     # == buildn autoencoder ==\n",
    "#     model_ae = build_module(cfg.ae, MODELS, device_map=device, torch_dtype=dtype).eval().requires_grad_(False)\n",
    "#     del model_ae.decoder\n",
    "#     log_cuda_memory(\"autoencoder\")\n",
    "#     log_model_params(model_ae)\n",
    "#     model_ae.encode = torch.compile(model_ae.encoder, dynamic=True)\n",
    "\n",
    "# if not cfg.get(\"cached_text\", False):\n",
    "#     # == build text encoder (t5) ==\n",
    "#     model_t5 = build_module(cfg.t5, MODELS, device_map=device, torch_dtype=dtype).eval().requires_grad_(False)\n",
    "#     log_cuda_memory(\"t5\")\n",
    "#     log_model_params(model_t5)\n",
    "\n",
    "#     # == build text encoder (clip) ==\n",
    "#     model_clip = build_module(cfg.clip, MODELS, device_map=device, torch_dtype=dtype).eval().requires_grad_(False)\n",
    "#     log_cuda_memory(\"clip\")\n",
    "#     log_model_params(model_clip)\n",
    "\n",
    "# # == setup optimizer ==\n",
    "# optimizer = create_optimizer(model, cfg.optim)\n",
    "\n",
    "# # == setup lr scheduler ==\n",
    "# lr_scheduler = create_lr_scheduler(\n",
    "#     optimizer=optimizer,\n",
    "#     num_steps_per_epoch=num_steps_per_epoch,\n",
    "#     epochs=cfg.get(\"epochs\", 1000),\n",
    "#     warmup_steps=cfg.get(\"warmup_steps\", None),\n",
    "#     use_cosine_scheduler=cfg.get(\"use_cosine_scheduler\", False),\n",
    "# )\n",
    "# log_cuda_memory(\"optimizer\")\n",
    "\n",
    "# # == prepare null vectors for dropout ==\n",
    "# if cfg.get(\"cached_text\", False):\n",
    "#     null_txt = torch.load(\"/mnt/ddn/sora/tmp_load/null_t5.pt\", map_location=device)\n",
    "#     null_vec = torch.load(\"/mnt/ddn/sora/tmp_load/null_clip.pt\", map_location=device)\n",
    "# else:\n",
    "#     null_txt = model_t5(\"\")\n",
    "#     null_vec = model_clip(\"\")\n",
    "\n",
    "# # =======================================================\n",
    "# # 4. distributed training preparation with colossalai\n",
    "# # =======================================================\n",
    "# logger.info(\"Preparing for distributed training...\")\n",
    "# # == boosting ==\n",
    "# torch.set_default_dtype(dtype)\n",
    "# model, optimizer, _, dataloader, lr_scheduler = booster.boost(\n",
    "#     model=model,\n",
    "#     optimizer=optimizer,\n",
    "#     lr_scheduler=lr_scheduler,\n",
    "#     dataloader=dataloader,\n",
    "# )\n",
    "# torch.set_default_dtype(torch.float)\n",
    "# logger.info(\"Boosted model for distributed training\")\n",
    "# log_cuda_memory(\"boost\")\n",
    "\n",
    "# # == global variables ==\n",
    "# cfg_epochs = cfg.get(\"epochs\", 1000)\n",
    "# log_step = acc_step = 0\n",
    "# running_loss = 0.0\n",
    "# timers = Timers(record_time=cfg.get(\"record_time\", False), record_barrier=cfg.get(\"record_barrier\", False))\n",
    "# nsys = NsysProfiler(\n",
    "#     warmup_steps=cfg.get(\"nsys_warmup_steps\", 2),\n",
    "#     num_steps=cfg.get(\"nsys_num_steps\", 2),\n",
    "#     enabled=cfg.get(\"nsys\", False),\n",
    "# )\n",
    "# logger.info(\"Training for %s epochs with %s steps per epoch\", cfg_epochs, num_steps_per_epoch)\n",
    "\n",
    "# # == resume ==\n",
    "# load_master_weights = cfg.get(\"load_master_weights\", False)\n",
    "# save_master_weights = cfg.get(\"save_master_weights\", False)\n",
    "# start_epoch = cfg.get(\"start_epoch\", None)\n",
    "# start_step = cfg.get(\"start_step\", None)\n",
    "# if cfg.get(\"load\", None) is not None:\n",
    "#     logger.info(\"Loading checkpoint from %s\", cfg.load)\n",
    "\n",
    "#     lr_scheduler_to_load = lr_scheduler\n",
    "#     if cfg.get(\"update_warmup_steps\", False):\n",
    "#         lr_scheduler_to_load = None\n",
    "#     ret = checkpoint_io.load(\n",
    "#         booster,\n",
    "#         cfg.load,\n",
    "#         model=model,\n",
    "#         ema=ema,\n",
    "#         optimizer=optimizer,\n",
    "#         lr_scheduler=lr_scheduler_to_load,\n",
    "#         sampler=(\n",
    "#             None if start_step is not None else sampler\n",
    "#         ),  # if specify start step, set last_micro_batch_access_index of a new sampler instead\n",
    "#         include_master_weights=load_master_weights,\n",
    "#     )\n",
    "#     start_epoch = start_epoch if start_epoch is not None else ret[0]\n",
    "#     start_step = start_step if start_step is not None else ret[1]\n",
    "#     logger.info(\"Loaded checkpoint %s at epoch %s step %s\", cfg.load, ret[0], ret[1])\n",
    "\n",
    "#     # load optimizer and scheduler will overwrite some of the hyperparameters, so we need to reset them\n",
    "#     set_lr(optimizer, lr_scheduler, cfg.optim.lr, cfg.get(\"initial_lr\", None))\n",
    "#     set_eps(optimizer, cfg.optim.eps)\n",
    "\n",
    "#     if cfg.get(\"update_warmup_steps\", False):\n",
    "#         assert (\n",
    "#             cfg.get(\"warmup_steps\", None) is not None\n",
    "#         ), \"you need to set warmup_steps in order to pass --update-warmup-steps True\"\n",
    "#         # set_warmup_steps(lr_scheduler, cfg.warmup_steps)\n",
    "#         lr_scheduler.step(start_epoch * num_steps_per_epoch + start_step)\n",
    "#         logger.info(\"The learning rate starts from %s\", optimizer.param_groups[0][\"lr\"])\n",
    "# if start_step is not None:\n",
    "#     # if start step exceeds data length, go to next epoch\n",
    "#     if start_step > num_steps_per_epoch:\n",
    "#         start_epoch = (\n",
    "#             start_epoch + start_step // num_steps_per_epoch\n",
    "#             if start_epoch is not None\n",
    "#             else start_step // num_steps_per_epoch\n",
    "#         )\n",
    "#         start_step = start_step % num_steps_per_epoch\n",
    "# else:\n",
    "#     start_step = 0\n",
    "# sampler.set_step(start_step)\n",
    "# start_epoch = start_epoch if start_epoch is not None else 0\n",
    "# logger.info(\"Starting from epoch %s step %s\", start_epoch, start_step)\n",
    "\n",
    "# # == sharding EMA model ==\n",
    "# if ema is not None:\n",
    "#     model_sharding(ema)\n",
    "#     ema = ema.to(device)\n",
    "#     log_cuda_memory(\"sharding EMA\")\n",
    "\n",
    "# # == warmup autoencoder ==\n",
    "# if cfg.get(\"warmup_ae\", False):\n",
    "#     shapes = bucket_to_shapes(cfg.get(\"bucket_config\", None), batch_size=cfg.ae.batch_size)\n",
    "#     warmup_ae(model_ae, shapes, device, dtype)\n",
    "\n",
    "# # =======================================================\n",
    "# # 5. training iter\n",
    "# # =======================================================\n",
    "# sigma_min = cfg.get(\"sigma_min\", 1e-5)\n",
    "# accumulation_steps = cfg.get(\"accumulation_steps\", 1)\n",
    "# ckpt_every = cfg.get(\"ckpt_every\", 0)\n",
    "\n",
    "# if cfg.get(\"is_causal_vae\", False):\n",
    "#     prepare_visual_condition = prepare_visual_condition_causal\n",
    "# else:\n",
    "#     prepare_visual_condition = prepare_visual_condition_uncausal\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def prepare_inputs(batch):\n",
    "#     inp = dict()\n",
    "#     x = batch.pop(\"video\")\n",
    "#     y = batch.pop(\"text\")\n",
    "#     bs = x.shape[0]\n",
    "\n",
    "#     # == encode video ==\n",
    "#     with nsys.range(\"encode_video\"), timers[\"encode_video\"]:\n",
    "#         # == prepare condition ==\n",
    "#         if cfg.get(\"condition_config\", None) is not None:\n",
    "#             # condition for i2v & v2v\n",
    "#             x_0, cond = prepare_visual_condition(x, cfg.condition_config, model_ae)\n",
    "#             cond = pack(cond, patch_size=cfg.get(\"patch_size\", 2))\n",
    "#             inp[\"cond\"] = cond\n",
    "#         else:\n",
    "#             if cfg.get(\"cached_video\", False):\n",
    "#                 x_0 = batch.pop(\"video_latents\").to(device=device, dtype=dtype)\n",
    "#             else:\n",
    "#                 x_0 = model_ae.encode(x)\n",
    "\n",
    "#     # == prepare timestep ==\n",
    "#     # follow SD3 time shift, shift_alpha = 1 for 256px and shift_alpha = 3 for 1024px\n",
    "#     shift_alpha = get_res_lin_function()((x_0.shape[-1] * x_0.shape[-2]) // 4)\n",
    "#     # add temporal influence\n",
    "#     shift_alpha *= math.sqrt(x_0.shape[-3])  # for image, T=1 so no effect\n",
    "#     t = torch.sigmoid(torch.randn((bs), device=device))\n",
    "#     t = time_shift(shift_alpha, t).to(dtype)\n",
    "\n",
    "#     if cfg.get(\"cached_text\", False):\n",
    "#         # == encode text ==\n",
    "#         t5_embedding = batch.pop(\"text_t5\").to(device=device, dtype=dtype)\n",
    "#         clip_embedding = batch.pop(\"text_clip\").to(device=device, dtype=dtype)\n",
    "#         with nsys.range(\"encode_text\"), timers[\"encode_text\"]:\n",
    "#             inp_ = prepare_ids(x_0, t5_embedding, clip_embedding)\n",
    "#             inp.update(inp_)\n",
    "#             x_0 = pack(x_0, patch_size=cfg.get(\"patch_size\", 2))\n",
    "#     else:\n",
    "#         # == encode text ==\n",
    "#         with nsys.range(\"encode_text\"), timers[\"encode_text\"]:\n",
    "#             inp_ = prepare(\n",
    "#                 model_t5,\n",
    "#                 model_clip,\n",
    "#                 x_0,\n",
    "#                 prompt=y,\n",
    "#                 seq_align=seq_align,\n",
    "#                 patch_size=cfg.get(\"patch_size\", 2),\n",
    "#             )\n",
    "#             inp.update(inp_)\n",
    "#             x_0 = pack(x_0, patch_size=cfg.get(\"patch_size\", 2))\n",
    "\n",
    "#     # == dropout ==\n",
    "#     if cfg.get(\"dropout_ratio\", None) is not None:\n",
    "#         cur_null_txt = null_txt\n",
    "#         num_pad_null_txt = inp[\"txt\"].shape[1] - cur_null_txt.shape[1]\n",
    "#         if num_pad_null_txt > 0:\n",
    "#             cur_null_txt = torch.cat([cur_null_txt] + [cur_null_txt[:, -1:]] * num_pad_null_txt, dim=1)\n",
    "#         inp[\"txt\"] = dropout_condition(\n",
    "#             cfg.dropout_ratio.get(\"t5\", 0.0),\n",
    "#             inp[\"txt\"],\n",
    "#             cur_null_txt,\n",
    "#         )\n",
    "#         inp[\"y_vec\"] = dropout_condition(\n",
    "#             cfg.dropout_ratio.get(\"clip\", 0.0),\n",
    "#             inp[\"y_vec\"],\n",
    "#             null_vec,\n",
    "#         )\n",
    "\n",
    "#     # == prepare noise vector ==\n",
    "#     x_1 = torch.randn_like(x_0, dtype=torch.float32).to(device, dtype)\n",
    "#     t_rev = 1 - t\n",
    "#     x_t = t_rev[:, None, None] * x_0 + (1 - (1 - sigma_min) * t_rev[:, None, None]) * x_1\n",
    "#     inp[\"img\"] = x_t\n",
    "#     inp[\"timesteps\"] = t.to(dtype)\n",
    "#     inp[\"guidance\"] = torch.full((x_t.shape[0],), cfg.get(\"guidance\", 4), device=x_t.device, dtype=x_t.dtype)\n",
    "\n",
    "#     return inp, x_0, x_1\n",
    "\n",
    "# def run_iter(inp, x_0, x_1):\n",
    "#     if is_pipeline_enabled(plugin_type, plugin_config):\n",
    "#         inp[\"target\"] = (1 - sigma_min) * x_1 - x_0  # follow MovieGen, modify V_t accordingly\n",
    "#         with nsys.range(\"forward-backward\"), timers[\"forward-backward\"]:\n",
    "#             data_iter = iter([inp])\n",
    "#             if cfg.get(\"no_i2v_ref_loss\", False):\n",
    "#                 loss_fn = (\n",
    "#                     lambda out, input_: get_batch_loss(out, input_[\"target\"], input_.pop(\"masks\", None))\n",
    "#                     / accumulation_steps\n",
    "#                 )\n",
    "#             else:\n",
    "#                 loss_fn = (\n",
    "#                     lambda out, input_: F.mse_loss(out.float(), input_[\"target\"].float(), reduction=\"mean\")\n",
    "#                     / accumulation_steps\n",
    "#                 )\n",
    "#             loss = booster.execute_pipeline(data_iter, model, loss_fn, optimizer)[\"loss\"]\n",
    "#             loss = loss * accumulation_steps if loss is not None else loss\n",
    "#             loss_item = all_reduce_mean(loss.data.clone().detach())\n",
    "#     else:\n",
    "#         with nsys.range(\"forward\"), timers[\"forward\"]:\n",
    "#             model_pred = model(**inp)  # B, T, L\n",
    "#             v_t = (1 - sigma_min) * x_1 - x_0\n",
    "#             if cfg.get(\"no_i2v_ref_loss\", False):\n",
    "#                 loss = get_batch_loss(model_pred, v_t, inp.pop(\"masks\", None))\n",
    "#             else:\n",
    "#                 loss = F.mse_loss(model_pred.float(), v_t.float(), reduction=\"mean\")\n",
    "\n",
    "#         loss_item = all_reduce_mean(loss.data.clone().detach()).item()\n",
    "\n",
    "#         # == backward & update ==\n",
    "#         dist.barrier()\n",
    "#         with nsys.range(\"backward\"), timers[\"backward\"]:\n",
    "#             ctx = (\n",
    "#                 booster.no_sync(model, optimizer)\n",
    "#                 if cfg.get(\"plugin\", \"zero2\") in (\"zero1\", \"zero1-seq\") and (step + 1) % accumulation_steps != 0\n",
    "#                 else nullcontext()\n",
    "#             )\n",
    "#             with ctx:\n",
    "#                 booster.backward(loss=(loss / accumulation_steps), optimizer=optimizer)\n",
    "\n",
    "#     with nsys.range(\"optim\"), timers[\"optim\"]:\n",
    "#         if (step + 1) % accumulation_steps == 0:\n",
    "#             booster.checkpoint_io.synchronize()\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()\n",
    "#         if lr_scheduler is not None:\n",
    "#             lr_scheduler.step()\n",
    "\n",
    "#     # == update EMA ==\n",
    "#     if ema is not None:\n",
    "#         with nsys.range(\"update_ema\"), timers[\"update_ema\"]:\n",
    "#             update_ema(\n",
    "#                 ema,\n",
    "#                 model.unwrap(),\n",
    "#                 optimizer=optimizer,\n",
    "#                 decay=cfg.get(\"ema_decay\", 0.9999),\n",
    "#             )\n",
    "\n",
    "#     return loss_item\n",
    "\n",
    "# # =======================================================\n",
    "# # 6. training loop\n",
    "# # =======================================================\n",
    "# dist.barrier()\n",
    "# for epoch in range(start_epoch, cfg_epochs):\n",
    "#     # == set dataloader to new epoch ==\n",
    "#     sampler.set_epoch(epoch)\n",
    "#     dataloader_iter = iter(dataloader)\n",
    "#     logger.info(\"Beginning epoch %s...\", epoch)\n",
    "\n",
    "#     # == training loop in an epoch ==\n",
    "#     with tqdm(\n",
    "#         enumerate(dataloader_iter, start=start_step),\n",
    "#         desc=f\"Epoch {epoch}\",\n",
    "#         disable=not is_log_process(plugin_type, plugin_config),\n",
    "#         initial=start_step,\n",
    "#         total=num_steps_per_epoch,\n",
    "#     ) as pbar:\n",
    "#         pbar_iter = iter(pbar)\n",
    "\n",
    "#         # prefetch one for non-blocking data loading\n",
    "#         def fetch_data():\n",
    "#             step, batch = next(pbar_iter)\n",
    "#             # print(f\"==debug== rank{dist.get_rank()} {dataloader_iter.get_cache_info()}\")\n",
    "#             pinned_video = batch[\"video\"]\n",
    "#             batch[\"video\"] = pinned_video.to(device, dtype, non_blocking=True)\n",
    "#             return batch, step, pinned_video\n",
    "\n",
    "#         batch_, step_, pinned_video_ = fetch_data()\n",
    "\n",
    "#         for _ in range(start_step, num_steps_per_epoch):\n",
    "#             nsys.step()\n",
    "#             # == load data ===\n",
    "#             with nsys.range(\"load_data\"), timers[\"load_data\"]:\n",
    "#                 batch, step, pinned_video = batch_, step_, pinned_video_\n",
    "\n",
    "#                 if step + 1 < num_steps_per_epoch:\n",
    "#                     # only fetch new data if not last step\n",
    "#                     batch_, step_, pinned_video_ = fetch_data()\n",
    "\n",
    "#             # == run iter ==\n",
    "#             with nsys.range(\"iter\"), timers[\"iter\"]:\n",
    "#                 inp, x_0, x_1 = prepare_inputs(batch)\n",
    "#                 if cache_pin_memory:\n",
    "#                     dataloader_iter.remove_cache(pinned_video)\n",
    "#                 loss = run_iter(inp, x_0, x_1)\n",
    "\n",
    "#             # == update log info ==\n",
    "#             if loss is not None:\n",
    "#                 running_loss += loss\n",
    "\n",
    "#             # == log config ==\n",
    "#             global_step = epoch * num_steps_per_epoch + step\n",
    "#             actual_update_step = (global_step + 1) // accumulation_steps\n",
    "#             log_step += 1\n",
    "#             acc_step += 1\n",
    "\n",
    "#             # == logging ==\n",
    "#             if (global_step + 1) % accumulation_steps == 0:\n",
    "#                 if actual_update_step % cfg.get(\"log_every\", 1) == 0:\n",
    "#                     if is_log_process(plugin_type, plugin_config):\n",
    "#                         avg_loss = running_loss / log_step\n",
    "#                         # progress bar\n",
    "#                         pbar.set_postfix(\n",
    "#                             {\n",
    "#                                 \"loss\": avg_loss,\n",
    "#                                 \"global_grad_norm\": optimizer.get_grad_norm(),\n",
    "#                                 \"step\": step,\n",
    "#                                 \"global_step\": global_step,\n",
    "#                                 # \"actual_update_step\": actual_update_step,\n",
    "#                                 \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "#                             }\n",
    "#                         )\n",
    "#                         # tensorboard\n",
    "#                         if tb_writer is not None:\n",
    "#                             tb_writer.add_scalar(\"loss\", loss, actual_update_step)\n",
    "#                         # wandb\n",
    "#                         if cfg.get(\"wandb\", False):\n",
    "#                             wandb_dict = {\n",
    "#                                 \"iter\": global_step,\n",
    "#                                 \"acc_step\": acc_step,\n",
    "#                                 \"epoch\": epoch,\n",
    "#                                 \"loss\": loss,\n",
    "#                                 \"avg_loss\": avg_loss,\n",
    "#                                 \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "#                                 \"eps\": optimizer.param_groups[0][\"eps\"],\n",
    "#                                 \"global_grad_norm\": optimizer.get_grad_norm(),  # test grad norm\n",
    "#                             }\n",
    "#                             if cfg.get(\"record_time\", False):\n",
    "#                                 wandb_dict.update(timers.to_dict())\n",
    "#                             wandb.log(wandb_dict, step=actual_update_step)\n",
    "\n",
    "#                     running_loss = 0.0\n",
    "#                     log_step = 0\n",
    "\n",
    "#             # == checkpoint saving ==\n",
    "#             # uncomment below 3 lines to forcely clean cache\n",
    "#             with nsys.range(\"clean_cache\"), timers[\"clean_cache\"]:\n",
    "#                 if ckpt_every > 0 and actual_update_step % ckpt_every == 0 and coordinator.is_master():\n",
    "#                     subprocess.run(\"sudo drop_cache\", shell=True)\n",
    "\n",
    "#             with nsys.range(\"checkpoint\"), timers[\"checkpoint\"]:\n",
    "#                 if ckpt_every > 0 and actual_update_step % ckpt_every == 0:\n",
    "#                     # mannual garbage collection\n",
    "#                     gc.collect()\n",
    "\n",
    "#                     save_dir = checkpoint_io.save(\n",
    "#                         booster,\n",
    "#                         exp_dir,\n",
    "#                         model=model,\n",
    "#                         ema=ema,\n",
    "#                         optimizer=optimizer,\n",
    "#                         lr_scheduler=lr_scheduler,\n",
    "#                         sampler=sampler,\n",
    "#                         epoch=epoch,\n",
    "#                         step=step + 1,\n",
    "#                         global_step=global_step + 1,\n",
    "#                         batch_size=cfg.get(\"batch_size\", None),\n",
    "#                         lora=use_lora,\n",
    "#                         actual_update_step=actual_update_step,\n",
    "#                         ema_shape_dict=ema_shape_dict,\n",
    "#                         async_io=cfg.get(\"async_io\", False),\n",
    "#                         include_master_weights=save_master_weights,\n",
    "#                     )\n",
    "\n",
    "#                     if is_log_process(plugin_type, plugin_config):\n",
    "#                         os.system(f\"chgrp -R share {save_dir}\")\n",
    "\n",
    "#                     logger.info(\n",
    "#                         \"Saved checkpoint at epoch %s, step %s, global_step %s to %s\",\n",
    "#                         epoch,\n",
    "#                         step + 1,\n",
    "#                         actual_update_step,\n",
    "#                         save_dir,\n",
    "#                     )\n",
    "\n",
    "#                     # remove old checkpoints\n",
    "#                     rm_checkpoints(exp_dir, keep_n_latest=cfg.get(\"keep_n_latest\", -1))\n",
    "#                     logger.info(\"Removed old checkpoints and kept %s latest ones.\", cfg.get(\"keep_n_latest\", -1))\n",
    "#             # uncomment below 3 lines to benchmark checkpoint\n",
    "#             # if ckpt_every > 0 and actual_update_step % ckpt_every == 0:\n",
    "#             #     booster.checkpoint_io._sync_io()\n",
    "#             #     checkpoint_io._sync_io()\n",
    "#             # == terminal timer ==\n",
    "#             if cfg.get(\"record_time\", False):\n",
    "#                 print(timers.to_str(epoch, step))\n",
    "\n",
    "#     sampler.reset()\n",
    "#     start_step = 0\n",
    "# log_cuda_max_memory(\"final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg[\"plugin_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab605c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
